#!/usr/bin/python2
# -*- coding: utf-8 -*-
#
# Copyright Â© 2014 Samsung Electronics, Ltd.
#
# This program is free software: you can redistribute it and/or modify it
# under the terms of the GNU Lesser General Public License as published
# by the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

from datetime import datetime
import os
import re
import sys
import json
import string
import git
from argparse import ArgumentParser
from subprocess import (Popen, PIPE)
import subprocess

import CommonMark
from xml.etree import ElementTree
import urllib
from urlparse import urlparse, parse_qs, urlunparse

sys.path.insert(0, os.path.realpath(
        os.path.join(os.path.dirname(__file__), "..")))
from autotwiki.week import Week
from autotwiki.twiki_browser import TwikiBrowser

class Autotwiki(object):
    def __init__(self):
        # Parse options
        parser = ArgumentParser()
        parser.add_argument('--config', action='store', type=str, dest='config',
                            help='Use specified config file location',
                            default='~/.config/autotwiki/config.json')
        parser.add_argument('--debug', action='store_true', dest='debug',
                            help="Enable detailed debugging output",
                            default=False)
        parser.add_argument('--dry-run', action='store_true', dest='dryrun',
                            help="Do not update the remote website",
                            default=False)
        parser.add_argument('--new', action='store_true', dest='new',
                            help="Overwrite status page with new content generated from template",
                            default=False)
        parser.add_argument('-v', '--version', action='store_true', dest='version_and_exit',
                            help="Print version number and exit",
                            default=False)
        parser.add_argument('-w', '--week', action='store', type=int, dest='week_number',
                            help="Generate report for the given week number rather than current",
                            default=None)
        parser.add_argument('-y', '--year', action='store', type=int, dest='year_number',
                            help="Generate report for the given year",
                            default=None)
        self.options = parser.parse_args()

        # Configuration
        config_filename = os.path.expanduser(self.options.config)
        with open(config_filename, 'r') as f:
            self.config = json.load(f)

    @property
    def dryrun(self):
        if self.options.dryrun:
            return True
        return self.config.get('dry-run', False)

def load_file(fname):
    filename = os.path.expanduser(fname)
    with open(filename, 'r') as f:
        text = f.read()
    return text

def update_repository(repo):
    p = Popen(["hooks/update_repository", repo], shell=False, stdout=PIPE, stderr=PIPE)
    out, err = p.communicate()
    if p.returncode != 0:
        print "Error (%d) updating %s:" %(p.returncode, repo)
        print out
        sys.stderr.write(err)
    return p.returncode == 0

def measure(hook, target, regex, begin_date=None, end_date=None):
    """Executes hook and returns total number of commits"""
    total = 0
    begin = begin_date.strftime('%m-%d-%Y')
    end = end_date.strftime('%m-%d-%Y')

    repo = git.Repo(target)
    commit = repo.head.commit
    while datetime.date(datetime.fromtimestamp(commit.committed_date)) >= end_date:
        commit = commit.parents[0]
        if not commit.parents:
            break

    commited = []
    reviewed = []
    while datetime.date(datetime.fromtimestamp(commit.committed_date)) >= begin_date:
        if regex.search(commit.author.name):
            commited.append(commit)
        elif regex.search(commit.committer.name):
            reviewed.append(commit)
        if not commit.parents:
            break
        commit = commit.parents[0]

    return commited, reviewed


if __name__ == "__main__":
    # Configuration
    app = Autotwiki()

    if app.options.version_and_exit:
        print("autotwiki version 0.1")
        sys.exit(0)

    week = Week(app.options.week_number, app.options.year_number)
    week_0 = Week(0)

    local = True
    if not app.options.new:
        local = False
    if not app.dryrun:
        local = False

    stat_start_label = "<!-- start-statistics-table -->"
    stat_end_label = "<!-- end-statistics-table -->"
    page_params = {
        'username':                app.config['username'],
        'full_name':               app.config['username'],
        'week_number':             str(week.number),
        'week_string':             week.description(),
        'patch_table_rows':        stat_start_label + "\n",
        }
    row_template = load_file(app.config['row-template'])

    # Collect statistics
    author = re.compile(app.config['name'])
    #print("%-30s %10s %10s %10s" %("Repository", "This Week", "This Year", "All Time"))
    for project in app.config['projects']:
        row_params = {
            'project_name': project['name'],

            'patches_submitted_this_week': 0,
            'patches_committed_this_week': 0,
            'patches_reviewed_this_week': 0,
            'bugs_fixed_this_week': 0,
            'enhancements_this_week': 0,
            'new_features_this_week': 0,
            'patches_for_gbm_request_this_week': 0,

            'patches_submitted_this_year': 0,
            'patches_committed_this_year': 0,
            'patches_reviewed_this_year': 0,
            'bugs_fixed_this_year': 0,
            'enhancements_this_year': 0,
            'new_features_this_year': 0,
            'patches_for_gbm_request_this_year': 0,

            'patches_submitted_all_time': 0,
            'patches_committed_all_time': 0,
            'patches_reviewed_all_time': 0,
            'bugs_fixed_all_time': 0,
            'enhancements_all_time': 0,
            'new_features_all_time': 0,
            'patches_for_gbm_request_all_time': 0,
            }

        summary = ""
        for repo in project['repositories']:
            if not update_repository(repo['location']):
                sys.stderr.write("Error updating repository %s\n" %(repo['location']))
                sys.exit(1)

            # Patches
            c, r = measure("commits_per_author", repo['location'], author, week.begin, week.end)
            row_params['patches_committed_this_week'] += len(c)
            row_params['patches_reviewed_this_week'] += len(r)

            if c:
                m = "\n * Commited commits in %s:" % os.path.basename(repo['location'])
                print(m)
                summary += m + "\n"

                bugz = {}
                for commit in c:
                    message = commit.message.split("\n")

                    m = "    - %s: %s" % (commit.hexsha, message[0])

                    _id = None
                    for l in message:
                        if not 'bugzilla' in l:
                            continue
                        url = urlparse(l)
                        if "bugzilla" not in url.netloc:
                            continue

                        query = parse_qs(url.query)
                        _id = query.get('id')
                        if not _id:
                            continue
                        if isinstance(_id, list):
                            _id = _id[0]
                        url_parts = tuple(list(url)[:3] + ['', '', ''])
                        ids = bugz.get(url_parts, [])
                        ids.append(_id)
                        bugz[url_parts] = ids

                    if _id:
                        m += " (bug #%s)" % _id
                    summary += m + "\n"
                    print(m)

                for url_parts, ids in bugz.items():
                    query = {'id': ','.join(ids)}
                    query['ctype'] = 'xml'
                    url_parts = list(url_parts)
                    url_parts[4] = urllib.urlencode(query)
                    try:
                        res = urllib.urlopen(urlunparse(url_parts))
                    except Exception as e:
                        print("  + Could not properly check bugs status for: %s (%s)\n"
                            % (urlunparse(url_parts), e), Colors.FAIL)
                        continue

                    root = ElementTree.fromstring(res.read())
                    bugs = root.findall('./bug')
                    for bugelem in bugs:
                        severity = bugelem.findtext('./bug_severity')
                        print("     -> bug: %s, status: %s" % (_id, severity))

                        if 'enhancement' in severity:
                            row_params['enhancements_this_week'] += 1
                        else:
                            row_params['bugs_fixed_this_week'] += 1


            if r:
                m = " * Reviewed commits in %s:" % os.path.basename(repo['location'])
                print(m)
                summary += m + "\n"

                for commit in r:
                    m = "    - %s" % commit.message.split("\n")[0]
                    print(m)
                    summary += m + "\n"

            if app.options.year_number:
                print("Generating for year: %s" % year)
                c, r = measure("commits_per_author", repo['location'], author, week_0.begin, week.end)
                row_params['patches_committed_this_year'] += len(c)
                row_params['patches_reviewed_this_year'] += len(r)

            # c, r = measure("reviews_per_committer", repo['location'], author, None, week.end)
            # row_params['patches_committed_all_time'] += len(c)
            # row_params['patches_reviewed_all_time'] += len(r)



        # TODO: Pass the collected data to one or more formatters
        # TODO: Add the output of the formatters to params
        patch_table_row = string.Template(row_template).substitute(row_params)
        page_params['patch_table_rows'] += patch_table_row

    # Close off the patch_table_rows section
    page_params['patch_table_rows'] += "\n" + stat_end_label
    page_params['summary'] = CommonMark.commonmark(summary)

    # Prepare to interact with the remote twiki site
    print "Preparing to send to twiki"
    text = ''
    if not local:
        twiki = TwikiBrowser(app.config)
        twiki.set_debug(app.options.debug)

        # Retrieve the current status page text
        url = twiki.url_weekly_status(week)
        if not app.options.new:
            text = twiki.get_page(url)
        print "%s" % url

    # If current status page is empty, load from the template
    if len(text) < 100:
        # Topic looks like it hasn't been created yet
        print "Creating new page"
        text = load_file(app.config['status-template'])
    elif "start-statistics-table" in text:
        # TODO: Substitue the current table with "$patch_table_rows"
        print("TODO: Replace existing table")
        print
        print text
        print
        regex = "%s(.*)%s" %(stat_start_label, stat_end_label)
        text = re.sub(regex, '$patch_table_rows', text)
        print "After Substitution:"
        print
        print text

        sys.exit(1)

    text = string.Template(text).substitute(page_params)

    if app.dryrun:
        print page_params['patch_table_rows']
        print
        print text
        sys.exit(0)

    if not local:
        twiki.set_page(url, text)
